<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><title>kafka多线程消费保证跨区消费顺序一致性的研究 | ALifeBug</title><meta name="description" content="kafka多线程消费保证跨区消费顺序一致性的研究"><meta name="keywords" content="kafka"><meta name="author" content="Huang Qingshan"><meta name="copyright" content="Huang Qingshan"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="/img/favicon.ico"><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><meta http-equiv="x-dns-prefetch-control" content="on"><link rel="canonical" href="http://alifebug.github.io/2020/12/11/kafka%E5%A4%9A%E7%BA%BF%E7%A8%8B%E6%B6%88%E8%B4%B9%E4%BF%9D%E8%AF%81%E8%B7%A8%E5%8C%BA%E6%B6%88%E8%B4%B9%E9%A1%BA%E5%BA%8F%E4%B8%80%E8%87%B4%E6%80%A7%E7%9A%84%E7%A0%94%E7%A9%B6/"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:title" content="kafka多线程消费保证跨区消费顺序一致性的研究"><meta name="twitter:description" content="kafka多线程消费保证跨区消费顺序一致性的研究"><meta name="twitter:image" content="https://s2.ax1x.com/2019/11/04/Kv8O6U.jpg"><meta property="og:type" content="article"><meta property="og:title" content="kafka多线程消费保证跨区消费顺序一致性的研究"><meta property="og:url" content="http://alifebug.github.io/2020/12/11/kafka%E5%A4%9A%E7%BA%BF%E7%A8%8B%E6%B6%88%E8%B4%B9%E4%BF%9D%E8%AF%81%E8%B7%A8%E5%8C%BA%E6%B6%88%E8%B4%B9%E9%A1%BA%E5%BA%8F%E4%B8%80%E8%87%B4%E6%80%A7%E7%9A%84%E7%A0%94%E7%A9%B6/"><meta property="og:site_name" content="ALifeBug"><meta property="og:description" content="kafka多线程消费保证跨区消费顺序一致性的研究"><meta property="og:image" content="https://s2.ax1x.com/2019/11/04/Kv8O6U.jpg"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="prev" title="消息队列" href="http://alifebug.github.io/2020/12/11/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"><link rel="next" title="八大排序算法总结" href="http://alifebug.github.io/2020/12/11/%E5%85%AB%E5%A4%A7%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93/"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: {"defaultEncoding":2,"translateDelay":0,"cookieDomain":"https://xxx/","msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"简"},
  highlight_copy: 'true',
  highlight_lang: 'true',
  highlight_shrink: 'false',
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  bookmark: {
    title: '添加书签',
    message_prev: '按',
    message_next: '键将本页加入书签'
  },
  runtime_unit: '天',
  copyright: undefined,
  copy_copyright_js: false
  
}</script><meta name="generator" content="Hexo 4.2.0"></head><body><div id="header"> <div id="page-header"><span class="pull-left" id="blog_name"><a class="blog_title" id="site-name" href="/">ALifeBug</a></span><i class="fa fa-bars fa-fw toggle-menu pull-right close" aria-hidden="true"></i><span class="pull-right menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> 链接</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> 关于</span></a></div><div class="menus_item"><a class="site-page"><i class="fa-fw fa fa-list" aria-hidden="true"></i><span> 其他</span><i class="fa fa-chevron-down menus-expand" aria-hidden="true"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/music/"><i class="fa-fw fa fa-music"></i><span> 音乐</span></a></li><li><a class="site-page" href="/movies/"><i class="fa-fw fa fa-film"></i><span> 电影</span></a></li></ul></div><script>document.body.addEventListener('touchstart', function(){ });</script></div></span><span class="pull-right" id="search_button"></span></div></div><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="lozad avatar_img" src="https://cdn.jsdelivr.net/gh/jerryc127/CDN@latest/Photo/avatar.png" onerror="onerror=null;src='/img/friend_404.gif'"></div><div class="mobile_post_data"><div class="mobile_data_item is_center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">文章</div><div class="length_num">61</div></a></div></div><div class="mobile_data_item is_center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">标签</div><div class="length_num">44</div></a></div></div><div class="mobile_data_item is_center">     <div class="mobile_data_link"><a href="/categories/"><div class="headline">分类</div><div class="length_num">24</div></a></div></div></div><hr><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> 链接</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> 关于</span></a></div><div class="menus_item"><a class="site-page"><i class="fa-fw fa fa-list" aria-hidden="true"></i><span> 其他</span><i class="fa fa-chevron-down menus-expand" aria-hidden="true"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/music/"><i class="fa-fw fa fa-music"></i><span> 音乐</span></a></li><li><a class="site-page" href="/movies/"><i class="fa-fw fa fa-film"></i><span> 电影</span></a></li></ul></div><script>document.body.addEventListener('touchstart', function(){ });</script></div></div><div id="mobile-sidebar-toc"><div class="toc_mobile_headline">目录</div><ol class="toc_mobile_items"><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#kafka多线程消费保证跨区消费顺序一致性的研究"><span class="toc_mobile_items-number">1.</span> <span class="toc_mobile_items-text">kafka多线程消费保证跨区消费顺序一致性的研究</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#一-实际生产中因消费次序错乱引发的问题"><span class="toc_mobile_items-number">1.1.</span> <span class="toc_mobile_items-text">一. 实际生产中因消费次序错乱引发的问题</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#二-当前或者曾经使用过的改善方案"><span class="toc_mobile_items-number">1.2.</span> <span class="toc_mobile_items-text">二. 当前或者曾经使用过的改善方案</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#三-哪些场景会存在消费顺序错乱的问题"><span class="toc_mobile_items-number">1.3.</span> <span class="toc_mobile_items-text">三. 哪些场景会存在消费顺序错乱的问题</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-6"><a class="toc_mobile_items-link" href="#测试时需要导入的依赖"><span class="toc_mobile_items-number">1.3.0.0.0.1.</span> <span class="toc_mobile_items-text">测试时需要导入的依赖</span></a></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-5"><a class="toc_mobile_items-link" href="#测试时使用的代码"><span class="toc_mobile_items-number">1.3.0.0.1.</span> <span class="toc_mobile_items-text">测试时使用的代码</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-6"><a class="toc_mobile_items-link" href="#各种场景下的测试情况分析"><span class="toc_mobile_items-number">1.3.0.0.1.1.</span> <span class="toc_mobile_items-text">各种场景下的测试情况分析:</span></a></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-5"><a class="toc_mobile_items-link" href="#四-自定义分区场景下的一些测试"><span class="toc_mobile_items-number">1.3.0.0.2.</span> <span class="toc_mobile_items-text">四.自定义分区场景下的一些测试</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-6"><a class="toc_mobile_items-link" href="#自定义分区实现"><span class="toc_mobile_items-number">1.3.0.0.2.1.</span> <span class="toc_mobile_items-text">自定义分区实现</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-6"><a class="toc_mobile_items-link" href="#自定义分区测试"><span class="toc_mobile_items-number">1.3.0.0.2.2.</span> <span class="toc_mobile_items-text">自定义分区测试</span></a></li></ol></li></ol></li></ol></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#五-合理的多线程消费方式"><span class="toc_mobile_items-number">1.4.</span> <span class="toc_mobile_items-text">五. 合理的多线程消费方式</span></a></li></ol></li></ol></div></div><div id="body-wrap"><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true">     </i><div class="auto_open" id="sidebar"><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#kafka多线程消费保证跨区消费顺序一致性的研究"><span class="toc-number">1.</span> <span class="toc-text">kafka多线程消费保证跨区消费顺序一致性的研究</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#一-实际生产中因消费次序错乱引发的问题"><span class="toc-number">1.1.</span> <span class="toc-text">一. 实际生产中因消费次序错乱引发的问题</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#二-当前或者曾经使用过的改善方案"><span class="toc-number">1.2.</span> <span class="toc-text">二. 当前或者曾经使用过的改善方案</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#三-哪些场景会存在消费顺序错乱的问题"><span class="toc-number">1.3.</span> <span class="toc-text">三. 哪些场景会存在消费顺序错乱的问题</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#测试时需要导入的依赖"><span class="toc-number">1.3.0.0.0.1.</span> <span class="toc-text">测试时需要导入的依赖</span></a></li></ol></li><li class="toc-item toc-level-5"><a class="toc-link" href="#测试时使用的代码"><span class="toc-number">1.3.0.0.1.</span> <span class="toc-text">测试时使用的代码</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#各种场景下的测试情况分析"><span class="toc-number">1.3.0.0.1.1.</span> <span class="toc-text">各种场景下的测试情况分析:</span></a></li></ol></li><li class="toc-item toc-level-5"><a class="toc-link" href="#四-自定义分区场景下的一些测试"><span class="toc-number">1.3.0.0.2.</span> <span class="toc-text">四.自定义分区场景下的一些测试</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#自定义分区实现"><span class="toc-number">1.3.0.0.2.1.</span> <span class="toc-text">自定义分区实现</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#自定义分区测试"><span class="toc-number">1.3.0.0.2.2.</span> <span class="toc-text">自定义分区测试</span></a></li></ol></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#五-合理的多线程消费方式"><span class="toc-number">1.4.</span> <span class="toc-text">五. 合理的多线程消费方式</span></a></li></ol></li></ol></div></div></div><div id="content-outer"><div id="top-container" style="background-image: url(https://s2.ax1x.com/2019/11/04/Kv8O6U.jpg)"><div id="post-info"><div id="post-title"><div class="posttitle">kafka多线程消费保证跨区消费顺序一致性的研究</div></div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 发表于 2020-12-11<span class="post-meta__separator">|</span><i class="fa fa-history" aria-hidden="true"></i> 更新于 2020-12-11</time><span class="post-meta__separator mobile_hidden">|</span><span class="mobile_hidden"><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/kafka/">kafka</a></span><div class="post-meta-wordcount"><span>阅读量: </span><span id="busuanzi_value_page_pv"></span></div></div></div></div><div class="layout layout_post" id="content-inner">   <article id="post"><div class="article-container" id="post-content"><h1 id="kafka多线程消费保证跨区消费顺序一致性的研究"><a href="#kafka多线程消费保证跨区消费顺序一致性的研究" class="headerlink" title="kafka多线程消费保证跨区消费顺序一致性的研究"></a>kafka多线程消费保证跨区消费顺序一致性的研究</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">在公司使用Kafka的过程中,存在跨区消费顺序错乱导致的数据一致性问题</span><br><span class="line">而公司的业务场景,要求数据必须严格一致,所以这个问题一直让我们头疼</span><br><span class="line">最近,我特别抽出一段时间,就这个问题的产生场景做了一些测试,并结合之前的一些处理方案,整理出了这篇博客.</span><br><span class="line"></span><br><span class="line">其中博客内容的一,二两点介绍了我们实际业务场景遇到的问题和之前尝试的一些解决方案,不敢兴趣的可以从第三点开始阅读</span><br></pre></td></tr></table></figure>

<p><strong>本篇博客要点如下:</strong></p>
<p><strong>一.生产场景因消费次序错乱引发的问题</strong></p>
<p><strong>二.当前或者曾经使用过的改善方案</strong></p>
<p><strong>三.测试哪些场景会存在消费次序错乱的问题</strong></p>
<ul>
<li>测试时需要导入的依赖</li>
<li>生产端和消费端的测试代码</li>
<li>各个场景下的测试情况<ul>
<li>单分区生产,单线程消费</li>
<li>单分区生产,多线程消费</li>
<li>多分区生产,单线程消费</li>
<li>多分区生产,多线程消费</li>
<li>测试情况总结</li>
</ul>
</li>
</ul>
<p><strong>四.自定义分区场景下的一些测试</strong></p>
<ul>
<li>自定义分区实现</li>
<li>自定义分区测试<ul>
<li>使用Java提供的线程池ThreadPoolExecutor</li>
<li>使用SpringBoot提供的kafka api</li>
</ul>
</li>
</ul>
<p><strong>五.合理的多线程消费方式</strong></p>
<h2 id="一-实际生产中因消费次序错乱引发的问题"><a href="#一-实际生产中因消费次序错乱引发的问题" class="headerlink" title="一. 实际生产中因消费次序错乱引发的问题"></a>一. 实际生产中因消费次序错乱引发的问题</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">我们使用Kafka的主要场景是:</span><br><span class="line">生产端推送因交易产生的OGG队列文件给消费端--&gt;消费端对数据进行处理--&gt;数据落地到MongoDB</span><br><span class="line"></span><br><span class="line">消费次序错乱引发的问题主要表现在以下几个方面:</span><br><span class="line"></span><br><span class="line">1.  数据和源端不一致(这个是遭到投诉最多的问题)</span><br><span class="line">2.  数据重复(在不自定义Mongo主键的情况下,更新队列优先于插入队列处理)</span><br><span class="line">3.  数据缺失(在自定义Mongo主键的情况下,更新队列优先于插入队列处理(插入队列写入失败,更新队列因分片键原因没有写入交易日期,导致数据缺失))</span><br></pre></td></tr></table></figure>



<h2 id="二-当前或者曾经使用过的改善方案"><a href="#二-当前或者曾经使用过的改善方案" class="headerlink" title="二. 当前或者曾经使用过的改善方案"></a>二. 当前或者曾经使用过的改善方案</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">1. 更新队列API替换(针对数据重复和数据缺失场景)</span><br><span class="line">对于MongoTemplate API,更新时使用updateFirst或者updateMulti 方法 替换 upsert方法</span><br><span class="line">替代方法,在数据库没有该条数据时,不会插入, 该方案能够基本上解决数据重复和数据缺失的问题</span><br><span class="line">但会加重数据和源端不一致的问题</span><br><span class="line"></span><br><span class="line">2. 临时补丁上线(针对数据缺失场景)</span><br><span class="line">该补丁主要用于解决数据缺失的问题, 会在一定时间内自动补全数据库中不包含结算日期数据的日期信息,</span><br><span class="line">目前,该补丁大大缓解了数据缺失的问题</span><br><span class="line"></span><br><span class="line">3. 自定义分区</span><br><span class="line">通过自定义分区设置,将同一笔交易的所有数据发往同一个分区,保证同一笔交易按照发生时间的先后顺序进行消费,          就目前的观测来看很好的改善了数据一致性的问题</span><br></pre></td></tr></table></figure>



<h2 id="三-哪些场景会存在消费顺序错乱的问题"><a href="#三-哪些场景会存在消费顺序错乱的问题" class="headerlink" title="三. 哪些场景会存在消费顺序错乱的问题"></a>三. 哪些场景会存在消费顺序错乱的问题</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">对于kafka的使用,整体上可分为如下四种场景:</span><br><span class="line"></span><br><span class="line">a. 单分区生产,单线程消费</span><br><span class="line">b. 单分区生产,多线程消费</span><br><span class="line">c. 多分区生产,单线程消费</span><br><span class="line">d. 多分区生产,多线程消费</span><br><span class="line"></span><br><span class="line">测试时针对以下四种场景,不采用自定义分区</span><br><span class="line">其中 :测试的key为1~100的随机整数, 值为从0其递增的整数</span><br><span class="line">topic的创建和分区数的设置通过kafka manager工具,测试时多线程消费采用Java提供的线程池ThreadPoolExecutor</span><br><span class="line">日志使用的是slf4j框架,可以在程序运行的时候打印出执行时间,使用线程等关键信息</span><br><span class="line"></span><br><span class="line">通过打印日志值的情况,消费数据的时间,线程使用等消息来判断是否存在乱序问题</span><br><span class="line">12345678910111213</span><br></pre></td></tr></table></figure>



<h6 id="测试时需要导入的依赖"><a href="#测试时需要导入的依赖" class="headerlink" title="测试时需要导入的依赖"></a>测试时需要导入的依赖</h6><p>我测试时操作Kafka使用的是SpringBoot框架</p>
<p><strong>SpringBoot框架需要导入的依赖如下:</strong></p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.springframework.kafka&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;spring-kafka&lt;/artifactId&gt;</span><br><span class="line">    &lt;version&gt;2.2.7.RELEASE&lt;/version&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;</span><br><span class="line">    &lt;scope&gt;test&lt;/scope&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure>

<p>如果使用<strong>原生的Kafka需要导入如下依赖:</strong></p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.apache.kafka&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;kafka_2.12&lt;/artifactId&gt;</span><br><span class="line">    &lt;version&gt;2.3.0&lt;/version&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure>



<h5 id="测试时使用的代码"><a href="#测试时使用的代码" class="headerlink" title="测试时使用的代码"></a>测试时使用的代码</h5><p><strong>生产端的代码</strong></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> pers.xmr.kafka;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.KafkaProducer;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.Producer;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.ProducerRecord;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Properties;</span><br><span class="line"><span class="keyword">import</span> java.util.Random;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> xmr</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@date</span> 2019/7/31 15:10</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@description</span> kafka生产端测试</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MyProducer</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Properties properties =  MyProducer.getProperties();</span><br><span class="line">        Producer&lt;String, String&gt; producer = <span class="keyword">new</span> KafkaProducer&lt;&gt;(properties);</span><br><span class="line">        Random random = <span class="keyword">new</span> Random();</span><br><span class="line">        <span class="keyword">int</span> i = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">            producer.send(<span class="keyword">new</span> ProducerRecord&lt;String, String&gt;(<span class="string">"xmr_topic2"</span>, String.valueOf(random.nextInt(<span class="number">100</span>)),String.valueOf(i++)));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> Properties <span class="title">getProperties</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        Properties props = <span class="keyword">new</span> Properties();</span><br><span class="line">        props.put(<span class="string">"bootstrap.servers"</span>, <span class="string">"10.213.32.96:9092,10.213.32.97:9092,10.213.32.98:9092"</span>);</span><br><span class="line">        props.put(<span class="string">"acks"</span>, <span class="string">"all"</span>); <span class="comment">//判断是否发送成功,不成功会阻塞所有消息,性能低,但是可靠性高</span></span><br><span class="line">        props.put(<span class="string">"retries"</span>, <span class="number">0</span>); <span class="comment">// 请求失败不自动重试,启用重试,可能会出现消息重复</span></span><br><span class="line">        props.put(<span class="string">"batch.size"</span>, <span class="number">16384</span>); <span class="comment">//缓存区域大小</span></span><br><span class="line">        props.put(<span class="string">"linger.ms"</span>, <span class="number">1</span>);</span><br><span class="line">        props.put(<span class="string">"buffer.memory"</span>, <span class="number">33554432</span>); <span class="comment">// 生产者可用的缓存总量</span></span><br><span class="line">        props.put(<span class="string">"key.serializer"</span>, <span class="string">"org.apache.kafka.common.serialization.StringSerializer"</span>);</span><br><span class="line">        props.put(<span class="string">"value.serializer"</span>, <span class="string">"org.apache.kafka.common.serialization.StringSerializer"</span>);</span><br><span class="line">        <span class="keyword">return</span> props;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>消费端代码, 包含单线程消费和多线程消费</strong></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> pers.xmr.kafka;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.ConsumerRecord;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.ConsumerRecords;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.KafkaConsumer;</span><br><span class="line"><span class="keyword">import</span> org.slf4j.Logger;</span><br><span class="line"><span class="keyword">import</span> org.slf4j.LoggerFactory;</span><br><span class="line"><span class="keyword">import</span> org.springframework.scheduling.annotation.Async;</span><br><span class="line"><span class="keyword">import</span> org.springframework.stereotype.Service;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.*;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.*;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> xmr</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@date</span> 2019/7/31 15:45</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@description</span></span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Service</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MyConsumer</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> Logger logger = LoggerFactory.getLogger(getClass());</span><br><span class="line">    <span class="keyword">private</span> KafkaConsumer&lt;String, String&gt; consumer;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Properties props = MyConsumer.getProperties();</span><br><span class="line">        MyConsumer myConsumer = <span class="keyword">new</span> MyConsumer();</span><br><span class="line">        myConsumer.multiThread(props);</span><br><span class="line">        myConsumer.singleThread(props);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Async</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">multiThread</span><span class="params">(Properties props)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">        consumer = <span class="keyword">new</span> KafkaConsumer&lt;String, String&gt;(props);</span><br><span class="line">        consumer.subscribe(Collections.singletonList(<span class="string">"xmr_topic2"</span>));</span><br><span class="line">        execute();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">execute</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            ExecutorService executors = <span class="keyword">new</span> ThreadPoolExecutor(<span class="number">4</span>, <span class="number">4</span>, <span class="number">0L</span>, TimeUnit.MILLISECONDS,</span><br><span class="line">                    <span class="keyword">new</span> ArrayBlockingQueue&lt;Runnable&gt;(<span class="number">1000</span>), <span class="keyword">new</span> ThreadPoolExecutor.CallerRunsPolicy());</span><br><span class="line">            <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">                ConsumerRecords&lt;String, String&gt; records = consumer.poll(<span class="number">200</span>);</span><br><span class="line">                <span class="keyword">for</span> (<span class="keyword">final</span> ConsumerRecord record : records) &#123;</span><br><span class="line">                    <span class="comment">//获取新这个partition中的最后一条记录的offset并加1 那么这个位置就是下一次要提交的offset</span></span><br><span class="line">                    ConsumerRunner consumerRunner = <span class="keyword">new</span> ConsumerRunner(consumer, record);</span><br><span class="line">                    executors.submit(consumerRunner);</span><br><span class="line">                &#125;</span><br><span class="line">                consumer.commitAsync();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">finally</span> &#123;</span><br><span class="line">            consumer.close();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">singleThread</span><span class="params">(Properties props)</span> </span>&#123;</span><br><span class="line">        consumer = <span class="keyword">new</span> KafkaConsumer&lt;String, String&gt;(props);</span><br><span class="line">        consumer.subscribe(Collections.singletonList(<span class="string">"xmr_topic2"</span>));</span><br><span class="line">        ConsumerRunner consumerRunner = <span class="keyword">new</span> ConsumerRunner(consumer);</span><br><span class="line">        <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">            ConsumerRecords&lt;String, String&gt; records = consumer.poll(<span class="number">100</span>);</span><br><span class="line">            <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; record : records) &#123;</span><br><span class="line">                logger.info(<span class="string">"offset = "</span> + record.offset() + <span class="string">"partation = "</span> + record.partition()+ <span class="string">"key= "</span> +  record.key()+ <span class="string">"value= "</span> + record.value());</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Properties <span class="title">getProperties</span><span class="params">()</span></span>&#123;</span><br><span class="line">        Properties props = <span class="keyword">new</span> Properties();</span><br><span class="line">        props.put(<span class="string">"bootstrap.servers"</span>, <span class="string">"10.213.32.96:9092,10.213.32.97:9092,10.213.32.98:9092"</span>);</span><br><span class="line">        props.put(<span class="string">"group.id"</span>, <span class="string">"test2"</span>);</span><br><span class="line">        props.put(<span class="string">"enable.auto.commit"</span>, <span class="string">"true"</span>);</span><br><span class="line">        props.put(<span class="string">"auto.commit.interval.ms"</span>, <span class="string">"1000"</span>);</span><br><span class="line">        props.put(<span class="string">"key.deserializer"</span>, <span class="string">"org.apache.kafka.common.serialization.StringDeserializer"</span>);</span><br><span class="line">        props.put(<span class="string">"value.deserializer"</span>, <span class="string">"org.apache.kafka.common.serialization.StringDeserializer"</span>);</span><br><span class="line">        <span class="keyword">return</span> props;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ConsumerRunner</span> <span class="keyword">implements</span> <span class="title">Runnable</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> Logger logger = LoggerFactory.getLogger(getClass());</span><br><span class="line">    KafkaConsumer consumer;</span><br><span class="line">    ConsumerRecord record;</span><br><span class="line">    ConsumerRunner(KafkaConsumer consumer) &#123;</span><br><span class="line">        <span class="keyword">this</span>.consumer = consumer;</span><br><span class="line">    &#125;</span><br><span class="line">    ConsumerRunner(KafkaConsumer consumer, ConsumerRecord record) &#123;</span><br><span class="line">        <span class="keyword">this</span>.consumer = consumer;</span><br><span class="line">        <span class="keyword">this</span>.record = record;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        logger.info(<span class="string">"offset = "</span> + record.offset() + <span class="string">"partation = "</span> + record.partition()+ <span class="string">"key= "</span> +  record.key()+ <span class="string">"value= "</span> + record.value());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h6 id="各种场景下的测试情况分析"><a href="#各种场景下的测试情况分析" class="headerlink" title="各种场景下的测试情况分析:"></a>各种场景下的测试情况分析:</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">1. 单分区生产,单线程消费</span><br><span class="line">日志截取如下:</span><br><span class="line">10:00:04.710 [main] INFO pers.xmr.kafka.MyConsumer - offset &#x3D; 4246988partation &#x3D; 0key&#x3D; 28value&#x3D; 4246988</span><br><span class="line">10:00:04.710 [main] INFO pers.xmr.kafka.MyConsumer - offset &#x3D; 4246989partation &#x3D; 0key&#x3D; 42value&#x3D; 4246989</span><br><span class="line">10:00:04.710 [main] INFO pers.xmr.kafka.MyConsumer - offset &#x3D; 4246990partation &#x3D; 0key&#x3D; 25value&#x3D; 4246990</span><br><span class="line">10:00:04.710 [main] INFO pers.xmr.kafka.MyConsumer - offset &#x3D; 4246991partation &#x3D; 0key&#x3D; 95value&#x3D; 4246991</span><br><span class="line">10:00:04.710 [main] INFO pers.xmr.kafka.MyConsumer - offset &#x3D; 4246992partation &#x3D; 0key&#x3D; 6value&#x3D; 4246992</span><br><span class="line">10:00:04.710 [main] INFO pers.xmr.kafka.MyConsumer - offset &#x3D; 4246993partation &#x3D; 0key&#x3D; 96value&#x3D; 4246993</span><br><span class="line">10:00:04.710 [main] INFO pers.xmr.kafka.MyConsumer - offset &#x3D; 4246994partation &#x3D; 0key&#x3D; 35value&#x3D; 4246994</span><br><span class="line">从日志中可以看到, 主线程完全按照推送顺序进行消费,不存在顺序错乱问题</span><br></pre></td></tr></table></figure>



<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">2. 单分区生产,多线程消费</span><br><span class="line">日志截取如下:</span><br><span class="line">10:12:21.469 [pool-1-thread-2] INFO pers.xmr.kafka.ConsumerRunner - offset &#x3D; 3001649partation &#x3D; 0key&#x3D; 21value&#x3D; 3001649</span><br><span class="line">10:12:21.469 [pool-1-thread-4] INFO pers.xmr.kafka.ConsumerRunner - offset &#x3D; 3001650partation &#x3D; 0key&#x3D; 1value&#x3D; 3001650</span><br><span class="line">10:12:21.469 [pool-1-thread-2] INFO pers.xmr.kafka.ConsumerRunner - offset &#x3D; 3001651partation &#x3D; 0key&#x3D; 16value&#x3D; 3001651</span><br><span class="line">10:12:21.470 [pool-1-thread-2] INFO pers.xmr.kafka.ConsumerRunner - offset &#x3D; 3001653partation &#x3D; 0key&#x3D; 25value&#x3D; 3001653</span><br><span class="line">10:12:21.469 [pool-1-thread-1] INFO pers.xmr.kafka.ConsumerRunner - offset &#x3D; 3001652partation &#x3D; 0key&#x3D; 55value&#x3D; 3001652</span><br><span class="line">10:12:21.471 [pool-1-thread-1] INFO pers.xmr.kafka.ConsumerRunner - offset &#x3D; 3001655partation &#x3D; 0key&#x3D; 39value&#x3D; 3001655</span><br><span class="line"></span><br><span class="line">从日志中可以看到,尽管不同线程去消费同一分区的数据,但从时间上来看,消费的顺序确实是按照偏移量从小到大,因此也不存在顺序错乱问题</span><br></pre></td></tr></table></figure>



<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">3. 多分区生产,单线程消费</span><br><span class="line">日志截取如下 :</span><br><span class="line">10:05:26.650 [main] INFO pers.xmr.kafka.MyConsumer - offset &#x3D; 1058594partation &#x3D; 1key&#x3D; 25value&#x3D; 6231830</span><br><span class="line">10:05:26.650 [main] INFO pers.xmr.kafka.MyConsumer - offset &#x3D; 1058595partation &#x3D; 1key&#x3D; 16value&#x3D; 6231840</span><br><span class="line">10:05:26.650 [main] INFO pers.xmr.kafka.MyConsumer - offset &#x3D; 1058596partation &#x3D; 1key&#x3D; 65value&#x3D; 6231843</span><br><span class="line">10:05:26.650 [main] INFO pers.xmr.kafka.MyConsumer - offset &#x3D; 1058597partation &#x3D; 1key&#x3D; 16value&#x3D; 6231845</span><br><span class="line">10:05:26.650 [main] INFO pers.xmr.kafka.MyConsumer - offset &#x3D; 1058598partation &#x3D; 1key&#x3D; 29value&#x3D; 6231847</span><br><span class="line">10:05:26.650 [main] INFO pers.xmr.kafka.MyConsumer - offset &#x3D; 1058599partation &#x3D; 1key&#x3D; 73value&#x3D; 6231848</span><br><span class="line">10:05:26.660 [main] INFO pers.xmr.kafka.MyConsumer - offset &#x3D; 1058599partation &#x3D; 2key&#x3D; 73value&#x3D; 6231835</span><br><span class="line"></span><br><span class="line">这里,分区内消费顺序是一致的,但是分区间的顺序是错乱的比如说值为6231835,6231843的两条数据如果对应于同一笔交易,就会出现数据一致性的问题</span><br></pre></td></tr></table></figure>



<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">4. 多分区生产,多线程消费</span><br><span class="line">日志截取如下 :</span><br><span class="line">10:07:30.844 [pool-1-thread-3] INFO pers.xmr.kafka.ConsumerRunner - offset &#x3D; 1162772partation &#x3D; 2key&#x3D; 74value&#x3D; 5816608</span><br><span class="line">10:07:30.963 [pool-1-thread-2] INFO pers.xmr.kafka.ConsumerRunner - offset &#x3D; 1722708partation &#x3D; 3key&#x3D; 3value&#x3D; 5385007</span><br><span class="line">10:07:30.963 [pool-1-thread-2] INFO pers.xmr.kafka.ConsumerRunner - offset &#x3D; 1722711partation &#x3D; 3key&#x3D; 28value&#x3D; 5385022</span><br><span class="line"></span><br><span class="line">从以上三条日志可以看出,多分区,多线程的场景下,在不自定义分区的情形,面临的顺序错乱问题是很严峻的</span><br></pre></td></tr></table></figure>



<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">总结 : 多分区生产, 单线程消费.  和多分区生产,多线程消费两种场景会产生数据一致性问题</span><br><span class="line">注意 : 多分区生产,单线程消费  和单分区生产,多线程消费可能和我们预期的结果有所出入</span><br><span class="line">这里, 有两个误区 :</span><br><span class="line">a. kafka只能保证数据分区内有序, 不能保证数据全局有序</span><br><span class="line">b. 同一时刻,kafka的一个分区的数据只能被一个线程消费, 但不意味着,一个线程只会消费一个分区的数据</span><br></pre></td></tr></table></figure>



<h5 id="四-自定义分区场景下的一些测试"><a href="#四-自定义分区场景下的一些测试" class="headerlink" title="四.自定义分区场景下的一些测试"></a>四.自定义分区场景下的一些测试</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">针对多分区产生的问题,我们通过自定义分区来解决,</span><br><span class="line"></span><br><span class="line">自定义分区的要点:</span><br><span class="line">a. 保证数据基本均匀的落在每个分区</span><br><span class="line">b. 保证同一笔交易对应的所有流水在同一个分区</span><br></pre></td></tr></table></figure>



<h6 id="自定义分区实现"><a href="#自定义分区实现" class="headerlink" title="自定义分区实现"></a>自定义分区实现</h6><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br></pre></td><td class="code"><pre><span class="line">由于我们的Kafka生产端是使用OGG推送数据,自定义分区代码不够纯粹,所以关于自定义分区,我仅仅给出一个最简单的demo实现,其中关键是实现Partitioner接口</span><br><span class="line"><span class="number">1</span></span><br><span class="line"><span class="keyword">package</span> pers.xmr.kafka;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.Callback;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.KafkaProducer;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.ProducerRecord;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.RecordMetadata;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ProducerPartition</span> </span>&#123;</span><br><span class="line"> </span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span>  <span class="keyword">void</span> <span class="title">main</span><span class="params">(String args[])</span> </span>&#123;</span><br><span class="line">		<span class="comment">//1.配置生产者属性</span></span><br><span class="line">		Properties props = <span class="keyword">new</span> Properties();</span><br><span class="line">		<span class="comment">// Kafka服务端的主机名和端口号，可以是多个</span></span><br><span class="line">		props.put(<span class="string">"bootstrap.servers"</span>, <span class="string">"ip:9092"</span>);</span><br><span class="line">		<span class="comment">//配置发送的消息是否等待应答</span></span><br><span class="line">		props.put(<span class="string">"acks"</span>, <span class="string">"all"</span>);</span><br><span class="line">		<span class="comment">//配置消息发送失败的重试</span></span><br><span class="line">		props.put(<span class="string">"retries"</span>, <span class="number">0</span>);</span><br><span class="line">		<span class="comment">// 批量处理数据的大小：16kb</span></span><br><span class="line">		props.put(<span class="string">"batch.size"</span>, <span class="number">16384</span>);</span><br><span class="line">		<span class="comment">// 设置批量处理数据的延迟，单位：ms</span></span><br><span class="line">		props.put(<span class="string">"linger.ms"</span>, <span class="number">1</span>);</span><br><span class="line">		<span class="comment">// 设置内存缓冲区的大小</span></span><br><span class="line">		props.put(<span class="string">"buffer.memory"</span>, <span class="number">33554432</span>);</span><br><span class="line">		<span class="comment">//数据在发送之前一定要序列化</span></span><br><span class="line">		<span class="comment">// key序列化</span></span><br><span class="line">		props.put(<span class="string">"key.serializer"</span>, <span class="string">"org.apache.kafka.common.serialization.StringSerializer"</span>);</span><br><span class="line">		<span class="comment">// value序列化</span></span><br><span class="line">		props.put(<span class="string">"value.serializer"</span>, <span class="string">"org.apache.kafka.common.serialization.StringSerializer"</span>);</span><br><span class="line">		</span><br><span class="line">		<span class="comment">//设置分区</span></span><br><span class="line">		props.put(<span class="string">"partitioner.class"</span>, <span class="string">"cn.ysjh.Partition"</span>);</span><br><span class="line">		</span><br><span class="line">		</span><br><span class="line">        <span class="comment">//2.实例化KafkaProducer</span></span><br><span class="line">		KafkaProducer&lt;String, String&gt; producer = <span class="keyword">new</span> KafkaProducer&lt;&gt;(props);</span><br><span class="line">		<span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">50</span>; i &lt; <span class="number">100</span>; i++) &#123;</span><br><span class="line">	    <span class="comment">//3.调用Producer的send方法，进行消息的发送，每条待发送的消息，都必须封装为一个Record对象，接口回调</span></span><br><span class="line">			producer.send(<span class="keyword">new</span> ProducerRecord&lt;String, String&gt;(<span class="string">"test"</span>, <span class="string">"hello"</span>+i), <span class="keyword">new</span> Callback() &#123;</span><br><span class="line">				</span><br><span class="line">				<span class="meta">@Override</span></span><br><span class="line">				<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onCompletion</span><span class="params">(RecordMetadata arg0, Exception arg1)</span> </span>&#123;</span><br><span class="line">					<span class="keyword">if</span>(arg0!=<span class="keyword">null</span>) &#123;</span><br><span class="line">						System.out.println(arg0.partition()+<span class="string">"--"</span>+arg0.offset());</span><br><span class="line">					&#125;</span><br><span class="line">					</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;);</span><br><span class="line">		&#125;</span><br><span class="line">        <span class="comment">//4.close释放资源</span></span><br><span class="line">		producer.close();</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">package</span> pers.xmr.kafka;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.Partitioner;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.common.Cluster;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Partition</span> <span class="keyword">implements</span> <span class="title">Partitioner</span></span>&#123;</span><br><span class="line"> </span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">configure</span><span class="params">(Map&lt;String, ?&gt; arg0)</span> </span>&#123;</span><br><span class="line">		<span class="comment">// TODO Auto-generated method stub</span></span><br><span class="line">		</span><br><span class="line">	&#125;</span><br><span class="line"> </span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">close</span><span class="params">()</span> </span>&#123;</span><br><span class="line">		<span class="comment">// TODO Auto-generated method stub</span></span><br><span class="line">		</span><br><span class="line">	&#125;</span><br><span class="line"> </span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">partition</span><span class="params">(String arg0, Object arg1, <span class="keyword">byte</span>[] arg2, Object arg3, <span class="keyword">byte</span>[] arg4, Cluster arg5)</span> </span>&#123;</span><br><span class="line">		<span class="comment">// TODO Auto-generated method stub</span></span><br><span class="line">		<span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">	&#125;</span><br><span class="line"> </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h6 id="自定义分区测试"><a href="#自定义分区测试" class="headerlink" title="自定义分区测试"></a>自定义分区测试</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">显然, 多分区生产,单线程消费在进行自定义分区处理后, 一定能够保证同一笔交易按照发生时间先后顺序进行消费(因为都在一个分区里,依序消费)</span><br><span class="line">那么,多分区,多线程场景下使用自定义分区会完全解决顺序错乱的问题么?</span><br><span class="line">我采用当前最流行的两种多线程消费的框架来进行测试, 为了保证测试场景紧贴实际业务,我把我们的业务代码封装到了这两种框架里进行测试</span><br></pre></td></tr></table></figure>



<p><strong>1. 使用Java提供的线程池ThreadPoolExecutor</strong></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">实现要点 :  创建一个指定线程数量的线程池, 并将消费的逻辑封装在一个实现Runnable的类里面, 或者使用匿名内部类或者lambda表达式实现</span><br><span class="line">测试结果 :  </span><br><span class="line"><span class="number">2019</span>-<span class="number">08</span>-<span class="number">01</span> <span class="number">10</span>:<span class="number">51</span>:<span class="number">00</span>:<span class="number">443</span> INFO  [pool-<span class="number">1</span>-thread-<span class="number">5</span>]  c.y.b.p.e.s.i.HpstjnlServiceImpl - 读取到更新队列数据! AC_DT : <span class="number">20190720L</span>OG_NO: <span class="number">707812011734</span>TXN_STS: U</span><br><span class="line"><span class="number">2019</span>-<span class="number">08</span>-<span class="number">01</span> <span class="number">10</span>:<span class="number">51</span>:<span class="number">00</span>:<span class="number">445</span> INFO  [pool-<span class="number">1</span>-thread-<span class="number">2</span>]  c.y.b.p.e.s.i.HpstjnlServiceImpl - 读取到更新队列数据! AC_DT : <span class="number">20190720L</span>OG_NO: <span class="number">707812011734</span>TXN_STS: T</span><br><span class="line"><span class="number">2019</span>-<span class="number">08</span>-<span class="number">01</span> <span class="number">10</span>:<span class="number">51</span>:<span class="number">00</span>:<span class="number">530</span> INFO  [pool-<span class="number">1</span>-thread-<span class="number">4</span>]  c.y.b.p.e.s.i.HpstjnlServiceImpl - 读取到插入队列数据! AC_DT: <span class="number">20190720L</span>OG_NO: <span class="number">708613011826</span>TXN_STS: U</span><br><span class="line"><span class="number">2019</span>-<span class="number">08</span>-<span class="number">01</span> <span class="number">10</span>:<span class="number">51</span>:<span class="number">00</span>:<span class="number">558</span> INFO  [pool-<span class="number">1</span>-thread-<span class="number">2</span>]  c.y.b.p.e.s.i.HpstjnlServiceImpl - 读取到更新队列数据! AC_DT : <span class="number">20190720L</span>OG_NO: <span class="number">708613011826</span>TXN_STS: U</span><br><span class="line"><span class="number">2019</span>-<span class="number">08</span>-<span class="number">01</span> <span class="number">10</span>:<span class="number">51</span>:<span class="number">00</span>:<span class="number">560</span> INFO  [pool-<span class="number">1</span>-thread-<span class="number">5</span>]  c.y.b.p.e.s.i.HpstjnlServiceImpl - 读取到更新队列数据! AC_DT : <span class="number">20190720L</span>OG_NO: <span class="number">708613011826</span>TXN_STS: T</span><br><span class="line"></span><br><span class="line">从日志打印情况来看, 尽管使用了自定义分区,但是同一笔交易的流水被不同的线程处理, 严重不符合预期!</span><br></pre></td></tr></table></figure>



<p><strong>2. 使用SpringBoot提供的kafka api</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">实现要点 : 在需要监听的方法前添加如下注解 :  @KafkaListener(topics &#x3D; &quot;ogg_etl_serial&quot;) , topics后面跟的是需要监听的topic</span><br></pre></td></tr></table></figure>

<p><strong>下面介绍一个最简单的实现:</strong></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> pers.xmr.listener;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.Consumer;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.ConsumerRecord;</span><br><span class="line"><span class="keyword">import</span> org.slf4j.Logger;</span><br><span class="line"><span class="keyword">import</span> org.slf4j.LoggerFactory;</span><br><span class="line"><span class="keyword">import</span> org.springframework.beans.factory.annotation.Autowired;</span><br><span class="line"><span class="keyword">import</span> org.springframework.beans.factory.annotation.Qualifier;</span><br><span class="line"><span class="keyword">import</span> org.springframework.kafka.support.Acknowledgment;</span><br><span class="line"><span class="keyword">import</span> org.springframework.stereotype.Service;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> xmr</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@date</span> 2019/8/1 11:26</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@description</span></span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Service</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">KafkaListener</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> Logger logger = LoggerFactory.getLogger(getClass());</span><br><span class="line">  </span><br><span class="line">    <span class="meta">@KafkaListener</span>(topics = <span class="string">"ogg_etl_serial"</span>)</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">listen0</span><span class="params">(List&lt;ConsumerRecord&lt;?, ?&gt;&gt; records, Acknowledgment ack, Consumer&lt;?, ?&gt; consumer)</span></span>&#123;</span><br><span class="line">        <span class="keyword">for</span> (ConsumerRecord&lt;?, ?&gt; record : records) &#123;</span><br><span class="line">            logger.info(<span class="string">"offset = "</span> + record.offset() + <span class="string">"partation = "</span> + record.partition()+ <span class="string">"key= "</span> +  record.key()+ <span class="string">"value= "</span> + record.value());   </span><br><span class="line">        &#125;</span><br><span class="line">        ack.acknowledge();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="number">123456789101112131415161718192021222324252627282930</span></span><br><span class="line">这部分比较关键,所以多截取一些运行日志, 测试结果 :</span><br><span class="line">2019-08-01 14:24:07:592 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-5-C-1]  c.y.b.p.e.s.i.HpstjnlServiceImpl - 读取到插入队列数据! AC_DT: 20190720LOG_NO: 708385011794TXN_STS: U</span><br><span class="line">2019-08-01 14:24:07:641 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-5-C-1]  c.y.b.p.e.s.i.HpstjnlServiceImpl - 读取到更新队列数据! AC_DT : 20190720LOG_NO: 708385011794TXN_STS: U</span><br><span class="line">2019-08-01 14:24:07:812 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-5-C-1]  c.y.b.p.e.s.i.HpstjnlServiceImpl - 读取到更新队列数据! AC_DT : 20190720LOG_NO: 708385011794TXN_STS: T</span><br><span class="line">2019-08-01 14:24:07:878 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1]  org.mongodb.driver.connection - Opened connection [connectionId&#123;localValue:12&#125;] to 10.213.32.84:50000</span><br><span class="line">2019-08-01 14:24:08:245 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-5-C-1]  c.y.b.p.e.s.i.HpstjnlServiceImpl - 读取到插入队列数据! AC_DT: 20190720LOG_NO: 707299011675TXN_STS: U</span><br><span class="line">2019-08-01 14:24:08:292 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-5-C-1]  c.y.b.p.e.s.i.HpstjnlServiceImpl - 读取到更新队列数据! AC_DT : 20190720LOG_NO: 707299011675TXN_STS: U</span><br><span class="line">2019-08-01 14:24:08:409 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-5-C-1]  c.y.b.p.e.s.i.HpstjnlServiceImpl - 读取到更新队列数据! AC_DT : 20190720LOG_NO: 707299011675TXN_STS: T</span><br><span class="line">2019-08-01 14:24:08:553 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1]  c.y.b.p.e.s.i.HpstjnlServiceImpl - 读取到插入队列数据! AC_DT: 20190720LOG_NO: 707577011707TXN_STS: U</span><br><span class="line">2019-08-01 14:24:08:595 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1]  c.y.b.p.e.s.i.HpstjnlServiceImpl - 读取到更新队列数据! AC_DT : 20190720LOG_NO: 707577011707TXN_STS: U</span><br><span class="line">2019-08-01 14:24:08:753 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1]  c.y.b.p.e.s.i.HpstjnlServiceImpl - 读取到更新队列数据! AC_DT : 20190720LOG_NO: 707577011707TXN_STS: T</span><br><span class="line">2019-08-01 14:24:08:845 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-5-C-1]  c.y.b.p.e.s.i.HpstjnlServiceImpl - 读取到插入队列数据! AC_DT: 20190720LOG_NO: 708286011783TXN_STS: U</span><br><span class="line">2019-08-01 14:24:09:100 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-5-C-1]  c.y.b.p.e.s.i.HpstjnlServiceImpl - 读取到更新队列数据! AC_DT : 20190720LOG_NO: 708286011783TXN_STS: U</span><br><span class="line">2019-08-01 14:24:09:208 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-5-C-1]  c.y.b.p.e.s.i.HpstjnlServiceImpl - 读取到更新队列数据! AC_DT : 20190720LOG_NO: 708286011783TXN_STS: T</span><br><span class="line"></span><br><span class="line">在这里可以看到,同一笔交易的所有流水被同一个线程按照推送过来的时间先后顺序进行消费,符合预期!</span><br></pre></td></tr></table></figure>



<h2 id="五-合理的多线程消费方式"><a href="#五-合理的多线程消费方式" class="headerlink" title="五. 合理的多线程消费方式"></a>五. 合理的多线程消费方式</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">通过上述的一些测试,想要在自定义分区的前提下,保证消费顺序的一直性</span><br><span class="line">需要摒弃Java提供的线程池,使用springBoot提供的kafka api, </span><br><span class="line">由于框架把基本的实现都给我们封装好,所以使用起来非常简单,而且效果很好!</span><br><span class="line"></span><br><span class="line">最终: 通过自定义分区 + springBoot提供的kafka多线程消费方式, 基本上能够解决跨分区消费引发的乱序问题!</span><br></pre></td></tr></table></figure></div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">Huang Qingshan</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://alifebug.github.io/2020/12/11/kafka%E5%A4%9A%E7%BA%BF%E7%A8%8B%E6%B6%88%E8%B4%B9%E4%BF%9D%E8%AF%81%E8%B7%A8%E5%8C%BA%E6%B6%88%E8%B4%B9%E9%A1%BA%E5%BA%8F%E4%B8%80%E8%87%B4%E6%80%A7%E7%9A%84%E7%A0%94%E7%A9%B6/">http://alifebug.github.io/2020/12/11/kafka%E5%A4%9A%E7%BA%BF%E7%A8%8B%E6%B6%88%E8%B4%B9%E4%BF%9D%E8%AF%81%E8%B7%A8%E5%8C%BA%E6%B6%88%E8%B4%B9%E9%A1%BA%E5%BA%8F%E4%B8%80%E8%87%B4%E6%80%A7%E7%9A%84%E7%A0%94%E7%A9%B6/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank" rel="noopener">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://ALifeBug.github.io">ALifeBug</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/kafka/">kafka    </a></div><div class="post_share"><div class="social-share" data-image="https://s2.ax1x.com/2019/11/04/Kv8O6U.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js@1.0.16/dist/css/share.min.css"><script src="https://cdn.jsdelivr.net/npm/social-share.js@1.0.16/dist/js/social-share.min.js"></script></div></div><div class="post-reward"><a class="reward-button"><i class="fa fa-qrcode"></i> 打赏<div class="reward-main"><ul class="reward-all"><li class="reward-item"><img class="lozad post-qr-code__img" src="/img/wechat.png"><div class="post-qr-code__desc">微信</div></li><li class="reward-item"><img class="lozad post-qr-code__img" src="/img/alipay.png"><div class="post-qr-code__desc">支付宝</div></li></ul></div></a></div><nav class="pagination_post" id="pagination"><div class="prev-post pull-left"><a href="/2020/12/11/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"><img class="prev_cover lozad" data-src="https://s2.ax1x.com/2019/11/04/Kv8O6U.jpg" onerror="onerror=null;src='/img/404.jpg'"><div class="label">上一篇</div><div class="prev_info"><span>消息队列</span></div></a></div><div class="next-post pull-right"><a href="/2020/12/11/%E5%85%AB%E5%A4%A7%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93/"><img class="next_cover lozad" data-src="https://s2.ax1x.com/2019/11/04/Kv8O6U.jpg" onerror="onerror=null;src='/img/404.jpg'"><div class="label">下一篇</div><div class="next_info"><span>八大排序算法总结</span></div></a></div></nav></div></div><footer><div id="footer"><div class="copyright">&copy;2018 - 2020 By Huang Qingshan</div><div class="framework-info"><span>驱动 </span><a href="http://hexo.io" target="_blank" rel="noopener"><span>Hexo</span></a><span class="footer-separator">|</span><span>主题 </span><a href="https://github.com/jerryc127/hexo-theme-butterfly" target="_blank" rel="noopener"><span>Butterfly</span></a></div></div></footer></div><section class="rightside" id="rightside"><div id="rightside-config-hide"><i class="fa fa-book" id="readmode" title="阅读模式"></i><i class="fa fa-plus" id="font_plus" title="放大字体"></i><i class="fa fa-minus" id="font_minus" title="缩小字体"></i><a class="translate_chn_to_cht" id="translateLink" href="javascript:translatePage();" title="简繁转换">简</a><i class="nightshift fa fa-moon-o" id="nightshift" title="夜间模式"></i></div><div id="rightside-config-show"><div id="rightside_config" title="设置"><i class="fa fa-cog" aria-hidden="true"></i></div><a id="to_comment" href="#post-comment" title="直达评论"><i class="scroll_to_comment fa fa-comments">  </i></a><i class="fa fa-list-ul close" id="mobile-toc-button" title="目录" aria-hidden="true"></i><i class="fa fa-arrow-up" id="go-up" title="回到顶部" aria-hidden="true"></i></div></section><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/js-cookie@2/src/js.cookie.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/nightshift.js"></script><script src="/js/tw_cn.js"></script><script>translateInitilization()

</script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page@1.2.2/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/lozad/dist/lozad.min.js"></script><script>const observer = lozad(); // lazy loads elements with default selector as '.lozad'
observer.observe();
</script></body></html>